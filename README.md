# BiasedMind

A method to measure attitude polarization caused by preferential feeds 

The internet age has bombarded us with information (and opinions). Today you will find almost all possible viewpoints on a particular subject available on internet, the view or opinion range from extremely positive in favour of the subject to extremely negative and some totally orthogonal. However, there are only few platforms that one can use to access the information available on internet, and, unfortunately all such platforms have some backend algorithm that filter the information and provide you with limited range of views on a subject. This is what is causing the polarization to an extent that is swaying governments now.
To understand and measure how preferred feeds, such as personalized news, the behaviour of individuals who are same or similar in all respects except for their news reading habits needs to be studied. There are many proposed methods for understanding the behaviour of individuals to check their inclination or deviation from certain normal, these are mostly questionnaire-based interviews with individuals. However, it is very difficult to isolate the real reason for deviation, is it because of personalized news or is it because of a documentary that they watched or is it because of an incident that happened with them in past, making such studies very difficult to conduct. Such studies give only directional (read correlation) predictions, not because of any flaw in method, but because it is very difficult to setup up ideal experiment conditions of conducting study on similar individuals. In contrast, other branches of science that conduct experiments, for example in chemistry to check how temperature affects certain reaction, a chemist can keep all other aspect of experiment same while changing just temperature and can understand the relation of temperature and the chemical reaction, can create ideal set of test samples having same or similar properties for all parameters (except the parameter that experimenter wants to vary). This problem has plagued psychology experiments since the beginning causing them to do only statistical analysis.

With the advent of machine learning and artificial intelligent algorithms, specifically, neural network-based machine learning, developers have tried to mimic how biological neural systems (human brain) process data and generates inferences. Today, developers have created models based on neural network that can not only correctly determine persons in photographs but have also evolved in other areas where they are being used to generate images, texts and even music.

Neural networks-based computer learning models are now able to learn from the real-world data (data could be numbers, images, sounds, texts, etc.) and are able to accomplish tasks that were earlier thought that only humans are efficient in. Since, such models are so closely mimicking human thinking process, we might consider such models to understand (and therefore predict) what a human will do. For a simple example, a model trained to recognize animals in a picture, can be used to understand what a human will respond when shown an image with animals and asked to name the animals (which brings us very close to Turing test). We donâ€™t want exact replica of human or human mind to study (we have been studying rats & guinea pigs for deriving psychological principals) but only human or human mind equivalence.

Neural models, if utilized, will be simple blank human mind replica that can be trained and observed in perfect lab conditions. It also provides an advantage of virtually creating as many mind replicas as required, limited only by the available computing resource. Using this if want to understand how preferred news is changing behaviour, we can create multiple neural models and train each of them with different version of preferred news as different human individuals would have received and read them. Once trained, the models can be studied for their differences, like word associations, etc.

To check if this method of evaluating biased-learned human-mimicking neural models can actually work, I first simplified the problem and checked how simpler models based for number recognition in image behave for biased environment, since, these models are easy to create and there are ample databases available for training such models. A simple number recognition model learns various features, that will help it to correctly associate an image of number with actual number, by first going through numerous images of numbers which have been correctly pre-identified (by humans) i.e., the model is trained using some training samples of handwritten number images which have been correctly labelled with correct number. Models trained like this have reached accuracy rate of 99.5+% when identifying an image of handwritten number which it has not previously seen.

The setup, for such an experiment, would require creating a neural network model that can be trained to recognize numeral in the images. A set of training images is required for the same, together with, a set of testing images, on which the trained models can be tested to check the variation in their prediction. Such an experiment will show that by preferentially varying the ratio of images for training the model, models will show a preferential prediction to certain set of numerals for which the ratios were higher. Which can be further generalized as different models trained by varying biased input information will have biased prediction while predicting on same (but different from input) set of information. 
